# -*- coding: utf-8 -*-
"""Mdel Selection in ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1owlzBKW_l0UjcufR-ulcal7VgJnYBXw2

Import Dependencies
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

"""import models"""

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

# loading csv dataframe of csv
heart_disease = pd.read_csv("/content/heart_disease_data.csv")
heart_disease.head()

# shape of data sset
heart_disease.shape

# missing value
heart_disease.isna().sum()

# Duplicate value
heart_disease.duplicated().sum()

heart_disease['target'].value_counts()

"""1--> Defective Heart

0--> Healthy Heart
"""

# spliting data set features and target
x = heart_disease.drop(columns='target', axis=1)
y = heart_disease['target']
print(x)

print(y)

x = np.asarray(x)
y = np.asarray(y)

print(x)

"""**Model Selection**"""

# list he models
models = [LogisticRegression(max_iter=10000), SVC(kernel='linear'), KNeighborsClassifier(), RandomForestClassifier(random_state=0)]

def compare_models_cross_validation():
  for model in models:
    cv_score = cross_val_score(model, x, y, cv=5)

    mean_accuracy = sum(cv_score)/len(cv_score)
    mean_accuracy = mean_accuracy*100
    mean_accuracy = round(mean_accuracy, 2)

    print('Cross Validation accuracies for the', model, '=', cv_score)
    print('Mean Accuracy score for the ', model, '=', mean_accuracy, '%')
    print('--------------------------------------------------------------------------------------------------------------')

compare_models_cross_validation()

# llist of model
models_list = [LogisticRegression(max_iter=10000), SVC(), KNeighborsClassifier(), RandomForestClassifier(random_state=0)]

# creating a dictionary that contains hyperparameter

model_hyperparameters = {
    'log_reg_hyperparameters': {
        'C' : [1,5,10,20]
    },

    'svc_hyperparameter': {
        'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],
        'C' : [1,5,10,20]
    },

    'KNN_hyperparameters': {
        'n_neighbors' : [3,5,10]

    },

    'random_forest_hyperparameters' : {
        'n_estimators' : [10,20,50,100]

    }
}

type(model_hyperparameters)

model_key=list(model_hyperparameters.keys())
print(model_key)

model_hyperparameters['KNN_hyperparameters']

"""Applying GridSearchCV"""

def model_selection(list_of_models, hyperparameters_dictionary):
  result = []

  i = 0

  for model in list_of_models:
    key = model_key[i]

    params = hyperparameters_dictionary[key]
    i += 1

    print(model)
    print(params)

    classifier = GridSearchCV(model, params, cv=5)

    classifier.fit(x,y)

    result.append({
        'model used' : model,
        'highest score' : classifier.best_score_,
        'best hyperparameters' : classifier.best_params_
    })

  result_dataframe = pd.DataFrame(result, columns=['model used', 'highest score', 'best hyperparameters'])

  return result_dataframe

model_selection(models_list, model_hyperparameters)

